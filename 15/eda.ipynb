# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the cleaned data from ad_data.csv
ad_df = pd.read_csv("ad_data.csv")

# Plot the distribution of the performance metrics, such as CTR, CVR, CPC, and CPA
ad_df.hist(["CTR", "CVR", "CPC", "CPA"], figsize=(12,10))
plt.suptitle("Distribution of Performance Metrics")
plt.show()

# Plot the distribution of the ad-related features, such as ad_text, ad_image, and ad_placement
ad_df["ad_text_length"] = ad_df["ad_text"].str.len() # Create a new feature for the length of the ad text
ad_df["ad_image_size"] = ad_df["ad_image"].str.split("x").apply(lambda x: int(x[0]) * int(x[1])) # Create a new feature for the size of the ad image
fig, axes = plt.subplots(1, 3, figsize=(12,10))
sns.countplot(x="ad_placement", hue="churn", data=ad_df, ax=axes[0])
axes[0].set_title("Distribution of Ad Placement by Churn")
sns.boxplot(x="churn", y="ad_text_length", data=ad_df, ax=axes[1])
axes[1].set_title("Distribution of Ad Text Length by Churn")
sns.boxplot(x="churn", y="ad_image_size", data=ad_df, ax=axes[2])
axes[2].set_title("Distribution of Ad Image Size by Churn")
plt.suptitle("Distribution of Ad-Related Features")
plt.show()

# Plot the distribution of the content-related features, such as page_title, page_content, page_keywords, and page_topics
ad_df["page_title_length"] = ad_df["page_title"].str.len() # Create a new feature for the length of the page title
ad_df["page_content_length"] = ad_df["page_content"].str.len() # Create a new feature for the length of the page content
ad_df["page_keywords_count"] = ad_df["page_keywords"].str.split(",").apply(lambda x: len(x)) # Create a new feature for the number of page keywords
ad_df["page_topics_count"] = ad_df["page_topics"].str.split(",").apply(lambda x: len(x)) # Create a new feature for the number of page topics
fig, axes = plt.subplots(2, 2, figsize=(12,10))
sns.boxplot(x="churn", y="page_title_length", data=ad_df, ax=axes[0, 0])
axes[0, 0].set_title("Distribution of Page Title Length by Churn")
sns.boxplot(x="churn", y="page_content_length", data=ad_df, ax=axes[0, 1])
axes[0, 1].set_title("Distribution of Page Content Length by Churn")
sns.boxplot(x="churn", y="page_keywords_count", data=ad_df, ax=axes[1, 0])
axes[1, 0].set_title("Distribution of Page Keywords Count by Churn")
sns.boxplot(x="churn", y="page_topics_count", data=ad_df, ax=axes[1, 1])
axes[1, 1].set_title("Distribution of Page Topics Count by Churn")
plt.suptitle("Distribution of Content-Related Features")
plt.show()

# Plot the correlation matrix of the features and performance metrics
corr_matrix = ad_df.corr()
sns.heatmap(corr_matrix, annot=True, cmap="RdBu")
plt.title("Correlation Matrix of Features and Performance Metrics")
plt.show()

# Identify and remove outliers if needed
# For example, use boxplots or z-scores to detect outliers
# Here we will use z-scores as an example

# Define a function to calculate z-scores
def z_score(df, col):
    mean = df[col].mean()
    std = df[col].std()
    return (df[col] - mean) / std

# Apply the function to the numeric columns and filter out values that are more than 3 standard deviations away from the mean
numeric_cols = ["CTR", "CVR", "CPC", "CPA", "ad_text_length", "ad_image_size", "page_title_length", "page_content_length", "page_keywords_count", "page_topics_count"]
for col in numeric_cols:
    ad_df[col + "_z"] = z_score(ad_df, col)
    ad_df = ad_df[abs(ad_df[col + "_z"]) < 3]

# Drop the z-score columns
ad_df.drop([col + "_z" for col in numeric_cols], axis=1, inplace=True)

# Save the analysis in a Jupyter notebook named eda.ipynb
# To do this, copy and paste this code in a Jupyter notebook and run it
